{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d878ade1",
   "metadata": {},
   "source": [
    "# Code is split into 2 main parts\n",
    "# 1. Data visualisation\n",
    "# 2. NLP using gpt2-medium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa680b2a",
   "metadata": {},
   "source": [
    "# Data visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12421f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt \n",
    "sb.set() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f4b925",
   "metadata": {},
   "outputs": [],
   "source": [
    "moviesdata = pd.read_csv(\"tmdb_5000_movies.csv\")\n",
    "moviesdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac03acae",
   "metadata": {},
   "outputs": [],
   "source": [
    "moviesdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7532998",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = moviesdata.loc[:, [\"title\",\"budget\", \"revenue\", \"production_companies\", \"genres\"]]\n",
    "# dataframe.loc[rows, columns]\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa1df3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = movies.loc[movies['revenue'] == 0]\n",
    "mask1 = movies.loc[movies['revenue'] <= 500000]\n",
    "indexes_rev = mask.index.tolist()\n",
    "indexes_rev = mask1.index.tolist()\n",
    "\n",
    "mask = movies.loc[movies['budget'] == 0]\n",
    "mask1 = movies.loc[movies['budget'] <= 500000]\n",
    "indexes_budget = mask.index.tolist()\n",
    "indexes_budget = mask1.index.tolist()\n",
    "\n",
    "indexes_budget.extend(indexes_rev)\n",
    "list(set(indexes_budget))\n",
    "revenue = movies['revenue'].drop(indexes_budget)\n",
    "budget = movies['budget'].drop(indexes_budget)\n",
    "profit = revenue - budget\n",
    "movies = movies.drop(index=indexes_budget)\n",
    "movies[\"profit\"] = movies[\"revenue\"] - movies[\"budget\"]\n",
    "movies.head(84)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40520717",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Profit' : profit,\n",
    "        'Budget' : budget,\n",
    "        'Revenue' : revenue}\n",
    "df = pd.DataFrame(data)\n",
    "corr = df.corr()\n",
    "# Calculate the correlation matrixcorr = df.corr()\n",
    "# Create the heatmap using Seaborn\n",
    "sb.heatmap(corr, vmin=-1, vmax=1, annot=True, cmap='coolwarm')\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b78a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9b308e",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e396608",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.drop_duplicates(inplace=True)\n",
    "movies.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08447efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "def convert_cast(obj): # convert string of list to list \n",
    "    L = []\n",
    "    for i in ast.literal_eval(obj):\n",
    "# ast convert the string of the list into an actual list object. \n",
    "# literal_eval function evaluate the string representation of a list.\n",
    "        L.append(i['name'])\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702d1024",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_company(obj):\n",
    "    counter = 0\n",
    "    L = []\n",
    "    for i in ast.literal_eval(obj):\n",
    "        if counter !=1:\n",
    "            L.append(i['name'])\n",
    "            counter += 1\n",
    "        else:\n",
    "            break\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af09f733",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['genres'] = movies['genres'].apply(convert_cast)\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ee068a",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['production_companies'] = movies['production_companies'].apply(convert_company)\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b1a7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the maximum number of items in the lists\n",
    "max_items = movies['genres'].apply(len).max()\n",
    "max_items\n",
    "# Split the 'genres' column into separate columns\n",
    "for i in range(max_items):\n",
    "    movies[f'genres_{i+1}'] = movies['genres'].apply(lambda x: x[i] if len(x) > i else None)\n",
    "\n",
    "# Drop the original 'genres' column if desired\n",
    "movies = movies.drop(columns='genres')\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0deef122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the 90th percentile value of the 'numbers' column\n",
    "quantile = movies['profit'].quantile(0.90)\n",
    "\n",
    "# Filter the top 10% values of the 'numbers' column\n",
    "top_10_percent = movies[movies['profit'] > quantile]\n",
    "top_10_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0346f4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0df8781",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_percent.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cc7b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_percent_genres= top_10_percent[['genres_1', 'genres_2', 'genres_3', 'genres_4', 'genres_5','genres_6', \n",
    "                                              'genres_7']].melt().dropna()['value']\n",
    "top_10_percent_genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16e8cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1,1,figsize=(17,10))\n",
    "sb.countplot(x=top_10_percent_genres,order=top_10_percent_genres.value_counts().index)\n",
    "axes.tick_params(axis='x', rotation=45)\n",
    "axes.set_title('Top 10% movies Genres')\n",
    "axes.set_ylabel('Number of movies')\n",
    "axes.set_xlabel('Genre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242604af",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_percent_genres_counts = top_10_percent_genres.value_counts()\n",
    "top_3_genres = top_10_percent_genres_counts.head(3)\n",
    "print(top_3_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0647cf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = top_10_percent.sort_values(by='profit', ascending=False)\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2f2b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (movies[\"genres_1\"].isin([\"Adventure\", \"Action\", \"Comedy\"]) |\n",
    "        movies[\"genres_2\"].isin([\"Adventure\", \"Action\", \"Comedy\"]) |\n",
    "        movies[\"genres_3\"].isin([\"Adventure\", \"Action\", \"Comedy\"]) |\n",
    "        movies[\"genres_4\"].isin([\"Adventure\", \"Action\", \"Comedy\"]) |\n",
    "        movies[\"genres_5\"].isin([\"Adventure\", \"Action\", \"Comedy\"]) |\n",
    "        movies[\"genres_6\"].isin([\"Adventure\", \"Action\", \"Comedy\"]) |\n",
    "        movies[\"genres_7\"].isin([\"Adventure\", \"Action\", \"Comedy\"]))\n",
    "\n",
    "filtered_movies = movies[mask]\n",
    "filtered_movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46242da",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_movies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dac2ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "credits = pd.read_csv(\"tmdb_5000_credits.csv\")\n",
    "credits.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bb22f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the dataframes on the common column names\n",
    "merged_df = pd.merge(filtered_movies, credits, on='title') # Merge the Data Basd on the Title\n",
    "\n",
    "# Print the merged dataframe\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d73833",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.drop('movie_id', axis=1) # axis = 1 ensure the method operates along the columns, and not the rows.\n",
    "\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbf9bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def director(obj):\n",
    "    L=[]\n",
    "    for i in ast.literal_eval(obj):\n",
    "        if i['job']=='Director': # Example: \"job\": \"Director\", \"name\": \"Andrew Stanton\"\n",
    "            L.append(i['name'])\n",
    "            break         \n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a11a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['crew'] = merged_df['crew'].apply(director) # Change it into a list\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d458759",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_cast(obj):\n",
    "    counter = 0\n",
    "    L = []\n",
    "    for i in ast.literal_eval(obj):\n",
    "        if counter !=3:  # We only want the top 3 names\n",
    "            L.append(i['name'])\n",
    "            counter += 1\n",
    "        else:\n",
    "            break\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d8496e",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['cast'] = merged_df['cast'].apply(convert_cast)\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15efd3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the 'crew' column into separate columns\n",
    "for i in range(1):\n",
    "    merged_df[f'director'] = merged_df['crew'].apply(lambda x: x[i] if len(x) > i else None)\n",
    "#The lambda function is using the indexing operator ([i]) to extract the ith element from the list stored in x.\n",
    "#it is Anonymous functions are functions that are defined without a name\n",
    "#If the length of the list x is less than or equal to i, then the lambda function returns None\n",
    "# Drop the original 'crew' column \n",
    "merged_df = merged_df.drop(columns='crew')\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61cdbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty dictionaries to count the number of movies in each genre for each director\n",
    "action_counts = {}\n",
    "adventure_counts = {}\n",
    "comedy_counts = {}\n",
    "\n",
    "# Loop through each row of the merged_df DataFrame\n",
    "for index, row in merged_df.iterrows(): \n",
    "    # Iterrows iterates over each rows of data as a typle of index and row \n",
    "    director = row[\"director\"]\n",
    "    for i in range(1, 8):\n",
    "        genre = row[f\"genres_{i}\"]\n",
    "        if genre == \"Action\":\n",
    "            if director not in action_counts:\n",
    "                action_counts[director] = 0\n",
    "            action_counts[director] += 1\n",
    "        elif genre == \"Adventure\":\n",
    "            if director not in adventure_counts:\n",
    "                adventure_counts[director] = 0\n",
    "            adventure_counts[director] += 1\n",
    "        elif genre == \"Comedy\":\n",
    "            if director not in comedy_counts:\n",
    "                comedy_counts[director] = 0\n",
    "            comedy_counts[director] += 1\n",
    "\n",
    "# Sort the dictionaries by the number of movies in each genre in descending order\n",
    "top_action_directors = sorted(action_counts, key=action_counts.get, reverse=True)[:3]\n",
    "# Reverse = Descending Order and [:3] is to get the top 3 directors\n",
    "top_adventure_directors = sorted(adventure_counts, key=adventure_counts.get, reverse=True)[:3]\n",
    "top_comedy_directors = sorted(comedy_counts, key=comedy_counts.get, reverse=True)[:3]\n",
    "\n",
    "# Print out the top 3 directors for each genre\n",
    "print(\"Top 3 Directors with the Most Action Movies:\")\n",
    "for i, director in enumerate(top_action_directors):\n",
    "    print(f\"{i+1}. {director} ({action_counts[director]} Action movies)\")\n",
    "\n",
    "print(\"\\nTop 3 Directors with the Most Adventure Movies:\")\n",
    "for i, director in enumerate(top_adventure_directors):\n",
    "    print(f\"{i+1}. {director} ({adventure_counts[director]} Adventure movies)\")\n",
    "\n",
    "print(\"\\nTop 3 Directors with the Most Comedy Movies:\")\n",
    "for i, director in enumerate(top_comedy_directors):\n",
    "    print(f\"{i+1}. {director} ({comedy_counts[director]} Comedy movies)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300ba18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = []\n",
    "for director in top_action_directors:\n",
    "    counts.append({'Director': director , 'Genre': 'Action', 'Count': action_counts[director]})\n",
    "for director in top_adventure_directors:\n",
    "    counts.append({'Director': director, 'Genre': 'Adventure', 'Count': adventure_counts[director]})\n",
    "for director in top_comedy_directors:\n",
    "    counts.append({'Director': director, 'Genre': 'Comedy', 'Count': comedy_counts[director]})\n",
    "counts_df = pd.DataFrame(counts)\n",
    "\n",
    "counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f26518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create separate count DataFrames for each genre\n",
    "action_df = counts_df[counts_df['Genre'] == 'Action']\n",
    "adventure_df = counts_df[counts_df['Genre'] == 'Adventure']\n",
    "comedy_df = counts_df[counts_df['Genre'] == 'Comedy']\n",
    "\n",
    "# Create the figure and subplots\n",
    "f, axes = plt.subplots(1, 3, figsize=(18, 6), sharey = True)\n",
    "\n",
    "\n",
    "# Create the count plot for Action movies using seaborn\n",
    "sb.barplot(x=\"Director\", y=\"Count\", data=action_df, ax=axes[0], color='blue')\n",
    "axes[0].set_xlabel('Director')\n",
    "axes[0].set_ylabel('Movies')\n",
    "axes[0].set_title('Count of Action Movies For Director')\n",
    "\n",
    "# Create the count plot for Adventure movies using seaborn\n",
    "sb.barplot(x=\"Director\", y=\"Count\", data=adventure_df, ax=axes[1], color='green')\n",
    "axes[1].set_xlabel('Director')\n",
    "axes[1].set_ylabel('Movies')\n",
    "axes[1].set_title('Count of Adventure Movies For Director')\n",
    "\n",
    "# Create the count plot for Comedy movies using seaborn\n",
    "sb.barplot(x=\"Director\", y=\"Count\", data=comedy_df, ax=axes[2],color='red')\n",
    "axes[2].set_xlabel('Director')\n",
    "axes[2].set_ylabel('Movies')\n",
    "axes[2].set_title('Count of Comedy Movies For Director')\n",
    "\n",
    "plt.suptitle(\"Top 3 Directors with the Most Movies in Each Genre\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ded735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the 'cast' column into separate columns\n",
    "for i in range(3):\n",
    "    merged_df[f'cast_{i+1}'] = merged_df['cast'].apply(lambda x: x[i] if len(x) > i else None)\n",
    "#The lambda function is using the indexing operator ([i]) to extract the ith element from the list stored in x.\n",
    "#it is Anonymous functions are functions that are defined without a name\n",
    "#If the length of the list x is less than or equal to i, then the lambda function returns None\n",
    "\n",
    "# Drop the original 'cast' column \n",
    "merged_df = merged_df.drop(columns='cast')\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b0e787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty dictionaries to count the number of movies in each genre for each actor\n",
    "action_counts = {}\n",
    "adventure_counts = {}\n",
    "comedy_counts = {}\n",
    "\n",
    "# Loop through each row of the merged_df DataFrame and count for the \"cast_1\" column\n",
    "for index, row in merged_df.iterrows():\n",
    "    actor = row[\"cast_1\"] \n",
    "    if actor != \"\":\n",
    "        for i in range(1, 8):\n",
    "            genre = row[f\"genres_{i}\"]\n",
    "            if genre == \"Action\":\n",
    "                if actor not in action_counts:\n",
    "                    action_counts[actor] = 0\n",
    "                action_counts[actor] += 1\n",
    "            elif genre == \"Adventure\":\n",
    "                if actor not in adventure_counts:\n",
    "                    adventure_counts[actor] = 0\n",
    "                adventure_counts[actor] += 1\n",
    "            elif genre == \"Comedy\":\n",
    "                if actor not in comedy_counts:\n",
    "                    comedy_counts[actor] = 0\n",
    "                comedy_counts[actor] += 1\n",
    "\n",
    "# Sort the dictionaries by the number of movies in each genre in descending order\n",
    "top_action_actors = sorted(action_counts, key=action_counts.get, reverse=True)[:3]\n",
    "top_adventure_actors = sorted(adventure_counts, key=adventure_counts.get, reverse=True)[:3]\n",
    "top_comedy_actors = sorted(comedy_counts, key=comedy_counts.get, reverse=True)[:3]\n",
    "\n",
    "# Print out the top 3 actors for each genre\n",
    "print(\"Top 3 Actors in the Most Action Movies:\")\n",
    "for i, actor in enumerate(top_action_actors):\n",
    "    print(f\"{i+1}. {actor} ({action_counts[actor]} Action movies)\")\n",
    "\n",
    "print(\"\\nTop 3 Actors in the Most Adventure Movies:\")\n",
    "for i, actor in enumerate(top_adventure_actors):\n",
    "    print(f\"{i+1}. {actor} ({adventure_counts[actor]} Adventure movies)\")\n",
    "\n",
    "print(\"\\nTop 3 Actors in the Most Comedy Movies:\")\n",
    "for i, actor in enumerate(top_comedy_actors):\n",
    "    print(f\"{i+1}. {actor} ({comedy_counts[actor]} Comedy movies)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0ef9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = []\n",
    "for actor in top_action_actors:\n",
    "    counts.append({'Actor': actor, 'Genre': 'Action', 'Count': action_counts[actor]})\n",
    "for actor in top_adventure_actors:\n",
    "    counts.append({'Actor': actor, 'Genre': 'Adventure', 'Count': adventure_counts[actor]})\n",
    "for actor in top_comedy_actors:\n",
    "    counts.append({'Actor': actor, 'Genre': 'Comedy', 'Count': comedy_counts[actor]})\n",
    "counts_df = pd.DataFrame(counts)\n",
    "\n",
    "counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04817c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create separate count DataFrames for each genre\n",
    "action_df = counts_df[counts_df['Genre'] == 'Action']\n",
    "adventure_df = counts_df[counts_df['Genre'] == 'Adventure']\n",
    "comedy_df = counts_df[counts_df['Genre'] == 'Comedy']\n",
    "\n",
    "# Create the figure and subplots\n",
    "f, axes = plt.subplots(1, 3, figsize=(18, 6), sharey = True)\n",
    "\n",
    "# Create the count plot for Action movies using seaborn\n",
    "sb.barplot(x=\"Actor\", y=\"Count\", data=action_df, ax=axes[0],color='blue')\n",
    "axes[0].set_xlabel('Actor')\n",
    "axes[0].set_ylabel('Movies')\n",
    "axes[0].set_title('Count of Action Movies For Top 3 Actors 1')\n",
    "\n",
    "# Create the count plot for Adventure movies using seaborn\n",
    "sb.barplot(x=\"Actor\", y=\"Count\", data=adventure_df, ax=axes[1],color='green')\n",
    "axes[1].set_xlabel('Actor')\n",
    "axes[1].set_ylabel('Movies')\n",
    "axes[1].set_title('Count of Adventure Movies For Top 3 Actors 1')\n",
    "\n",
    "# Create the count plot for Comedy movies using seaborn\n",
    "sb.barplot(x=\"Actor\", y=\"Count\", data=comedy_df, ax=axes[2],color='red')\n",
    "axes[2].set_xlabel('Actor')\n",
    "axes[2].set_ylabel('Movies')\n",
    "axes[2].set_title('Count of Comedy Movies For Top 3 Actors 1')\n",
    "\n",
    "plt.suptitle(\"Top 3 Actor 1 by Genre\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13996921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty dictionaries to count the number of movies in each genre for each actor\n",
    "action_counts = {}\n",
    "adventure_counts = {}\n",
    "comedy_counts = {}\n",
    "\n",
    "# Loop through each row of the merged_df DataFrame and count for the \"cast_1\" column\n",
    "for index, row in merged_df.iterrows():\n",
    "    actor = row[\"cast_2\"]\n",
    "    if actor != \"\":\n",
    "        for i in range(1, 8):\n",
    "            genre = row[f\"genres_{i}\"]\n",
    "            if genre == \"Action\":\n",
    "                if actor not in action_counts:\n",
    "                    action_counts[actor] = 0\n",
    "                action_counts[actor] += 1\n",
    "            elif genre == \"Adventure\":\n",
    "                if actor not in adventure_counts:\n",
    "                    adventure_counts[actor] = 0\n",
    "                adventure_counts[actor] += 1\n",
    "            elif genre == \"Comedy\":\n",
    "                if actor not in comedy_counts:\n",
    "                    comedy_counts[actor] = 0\n",
    "                comedy_counts[actor] += 1\n",
    "\n",
    "# Sort the dictionaries by the number of movies in each genre in descending order\n",
    "top_action_actors = sorted(action_counts, key=action_counts.get, reverse=True)[:3]\n",
    "top_adventure_actors = sorted(adventure_counts, key=adventure_counts.get, reverse=True)[:3]\n",
    "top_comedy_actors = sorted(comedy_counts, key=comedy_counts.get, reverse=True)[:3]\n",
    "\n",
    "# Print out the top 3 actors for each genre\n",
    "print(\"Top 3 Actors 2 in the Most Action Movies:\")\n",
    "for i, actor in enumerate(top_action_actors):\n",
    "    print(f\"{i+1}. {actor} ({action_counts[actor]} Action movies)\")\n",
    "\n",
    "print(\"\\nTop 3 Actors 2 in the Most Adventure Movies:\")\n",
    "for i, actor in enumerate(top_adventure_actors):\n",
    "    print(f\"{i+1}. {actor} ({adventure_counts[actor]} Adventure movies)\")\n",
    "\n",
    "print(\"\\nTop 3 Actors 2 in the Most Comedy Movies:\")\n",
    "for i, actor in enumerate(top_comedy_actors):\n",
    "    print(f\"{i+1}. {actor} ({comedy_counts[actor]} Comedy movies)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405d252e",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = []\n",
    "for actor in top_action_actors:\n",
    "    counts.append({'Actor': actor, 'Genre': 'Action', 'Count': action_counts[actor]})\n",
    "for actor in top_adventure_actors:\n",
    "    counts.append({'Actor': actor, 'Genre': 'Adventure', 'Count': adventure_counts[actor]})\n",
    "for actor in top_comedy_actors:\n",
    "    counts.append({'Actor': actor, 'Genre': 'Comedy', 'Count': comedy_counts[actor]})\n",
    "counts_df = pd.DataFrame(counts)\n",
    "\n",
    "counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4fc6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create separate count DataFrames for each genre\n",
    "action_df = counts_df[counts_df['Genre'] == 'Action']\n",
    "adventure_df = counts_df[counts_df['Genre'] == 'Adventure']\n",
    "comedy_df = counts_df[counts_df['Genre'] == 'Comedy']\n",
    "\n",
    "# Create the figure and subplots\n",
    "f, axes = plt.subplots(1, 3, figsize=(18, 6),sharey = True)\n",
    "\n",
    "# Create the count plot for Action movies using seaborn\n",
    "sb.barplot(x=\"Actor\", y=\"Count\", data=action_df, ax=axes[0], color = \"blue\")\n",
    "axes[0].set_xlabel('Actor')\n",
    "axes[0].set_ylabel('Movies')\n",
    "axes[0].set_title('Count Of Action Movies For Top 3 Actors 2')\n",
    "\n",
    "# Create the count plot for Adventure movies using seaborn\n",
    "sb.barplot(x=\"Actor\", y=\"Count\", data=adventure_df, ax=axes[1], color = \"green\")\n",
    "axes[1].set_xlabel('Actor')\n",
    "axes[1].set_ylabel('Movies')\n",
    "axes[1].set_title('Count Of Adventure Movies For Top 3 Actors 2')\n",
    "\n",
    "# Create the count plot for Comedy movies using seaborn\n",
    "sb.barplot(x=\"Actor\", y=\"Count\", data=comedy_df, ax=axes[2], color = \"red\")\n",
    "axes[2].set_xlabel('Actor')\n",
    "axes[2].set_ylabel('Movies')\n",
    "axes[2].set_title('Count Of Comedy Movies For Top 3 Actors 2')\n",
    "\n",
    "plt.suptitle(\"Top 3 Actor 2 by Genre\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e88ef21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty dictionaries to count the number of movies in each genre for each actor\n",
    "action_counts = {}\n",
    "adventure_counts = {}\n",
    "comedy_counts = {}\n",
    "\n",
    "# Loop through each row of the merged_df DataFrame and count for the \"cast_1\" column\n",
    "for index, row in merged_df.iterrows():\n",
    "    actor = row[\"cast_3\"]\n",
    "    if actor != \"\":\n",
    "        for i in range(1, 8):\n",
    "            genre = row[f\"genres_{i}\"]\n",
    "            if genre == \"Action\":\n",
    "                if actor not in action_counts:\n",
    "                    action_counts[actor] = 0\n",
    "                action_counts[actor] += 1\n",
    "            elif genre == \"Adventure\":\n",
    "                if actor not in adventure_counts:\n",
    "                    adventure_counts[actor] = 0\n",
    "                adventure_counts[actor] += 1\n",
    "            elif genre == \"Comedy\":\n",
    "                if actor not in comedy_counts:\n",
    "                    comedy_counts[actor] = 0\n",
    "                comedy_counts[actor] += 1\n",
    "\n",
    "# Sort the dictionaries by the number of movies in each genre in descending order\n",
    "top_action_actors = sorted(action_counts, key=action_counts.get, reverse=True)[:3]\n",
    "top_adventure_actors = sorted(adventure_counts, key=adventure_counts.get, reverse=True)[:3]\n",
    "top_comedy_actors = sorted(comedy_counts, key=comedy_counts.get, reverse=True)[:3]\n",
    "\n",
    "# Print out the top 3 actors for each genre\n",
    "print(\"Top 3 Actors 3 in the Most Action Movies:\")\n",
    "for i, actor in enumerate(top_action_actors):\n",
    "    print(f\"{i+1}. {actor} ({action_counts[actor]} Action movies)\")\n",
    "\n",
    "print(\"\\nTop 3 Actors 3 in the Most Adventure Movies:\")\n",
    "for i, actor in enumerate(top_adventure_actors):\n",
    "    print(f\"{i+1}. {actor} ({adventure_counts[actor]} Adventure movies)\")\n",
    "\n",
    "print(\"\\nTop 3 Actors 3 in the Most Comedy Movies:\")\n",
    "for i, actor in enumerate(top_comedy_actors):\n",
    "    print(f\"{i+1}. {actor} ({comedy_counts[actor]} Comedy movies)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645870e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = []\n",
    "for actor in top_action_actors:\n",
    "    counts.append({'Actor': actor, 'Genre': 'Action', 'Count': action_counts[actor]})\n",
    "for actor in top_adventure_actors:\n",
    "    counts.append({'Actor': actor, 'Genre': 'Adventure', 'Count': adventure_counts[actor]})\n",
    "for actor in top_comedy_actors:\n",
    "    counts.append({'Actor': actor, 'Genre': 'Comedy', 'Count': comedy_counts[actor]})\n",
    "counts_df = pd.DataFrame(counts)\n",
    "\n",
    "counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07b2e84",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create separate count DataFrames for each genre\n",
    "action_df = counts_df[counts_df['Genre'] == 'Action']\n",
    "adventure_df = counts_df[counts_df['Genre'] == 'Adventure']\n",
    "comedy_df = counts_df[counts_df['Genre'] == 'Comedy']\n",
    "\n",
    "# Create the figure and subplots\n",
    "f, axes = plt.subplots(1, 3, figsize=(18, 6), sharey = True)\n",
    "\n",
    "# Create the count plot for Action movies using seaborn\n",
    "sb.barplot(x=\"Actor\", y=\"Count\", data=action_df, ax=axes[0],color = \"blue\")\n",
    "axes[0].set_xlabel('Actor')\n",
    "axes[0].set_ylabel('Movies')\n",
    "axes[0].set_title('Count Of Action Movies For Top 3 Actors 3')\n",
    "\n",
    "# Create the count plot for Adventure movies using seaborn\n",
    "sb.barplot(x=\"Actor\", y=\"Count\", data=adventure_df, ax=axes[1], color = \"green\")\n",
    "axes[1].set_xlabel('Actor')\n",
    "axes[1].set_ylabel('Movies')\n",
    "axes[1].set_title('Count Of Adventure Movies For Top 3 Actors 3')\n",
    "\n",
    "# Create the count plot for Comedy movies using seaborn\n",
    "sb.barplot(x=\"Actor\", y=\"Count\", data=comedy_df, ax=axes[2], color = \"red\")\n",
    "axes[2].set_xlabel('Actor')\n",
    "axes[2].set_ylabel('Movies')\n",
    "axes[2].set_title('Count Of Comedy Movies For Top 3 Actors 3')\n",
    "\n",
    "plt.suptitle(\"Top 3 Actor 3 by Genre\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215aff0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty dictionaries to count the number of movies in each genre for each production company\n",
    "action_counts = {}\n",
    "adventure_counts = {}\n",
    "comedy_counts = {}\n",
    "\n",
    "# Loop through each row of the prod_com DataFrame\n",
    "for index, row in merged_df.iterrows():\n",
    "    companies = row['production_companies']\n",
    "    for i in range(1, 8):\n",
    "        genre = row[f\"genres_{i}\"]\n",
    "        if genre == \"Action\":\n",
    "            for company in companies:\n",
    "                if company not in action_counts:\n",
    "                    action_counts[company] = 0\n",
    "                action_counts[company] += 1\n",
    "        elif genre == \"Adventure\":\n",
    "            for company in companies:\n",
    "                if company not in adventure_counts:\n",
    "                    adventure_counts[company] = 0\n",
    "                adventure_counts[company] += 1\n",
    "        elif genre == \"Comedy\":\n",
    "            for company in companies:\n",
    "                if company not in comedy_counts:\n",
    "                    comedy_counts[company] = 0\n",
    "                comedy_counts[company] += 1\n",
    "\n",
    "# Sort the dictionaries by the number of movies in each genre in descending order\n",
    "top_action_companies = sorted(action_counts, key=action_counts.get, reverse=True)[:3]\n",
    "top_adventure_companies = sorted(adventure_counts, key=adventure_counts.get, reverse=True)[:3]\n",
    "top_comedy_companies = sorted(comedy_counts, key=comedy_counts.get, reverse=True)[:3]\n",
    "\n",
    "# Print out the top 3 production companies for each genre\n",
    "print(\"Top 3 Production Companies with the Most Action Movies:\")\n",
    "for i, company in enumerate(top_action_companies):\n",
    "    print(f\"{i+1}. {company} ({action_counts[company]} Action movies)\")\n",
    "\n",
    "print(\"\\nTop 3 Production Companies with the Most Adventure Movies:\")\n",
    "for i, company in enumerate(top_adventure_companies):\n",
    "    print(f\"{i+1}. {company} ({adventure_counts[company]} Adventure movies)\")\n",
    "\n",
    "print(\"\\nTop 3 Production Companies with the Most Comedy Movies:\")\n",
    "for i, company in enumerate(top_comedy_companies):\n",
    "    print(f\"{i+1}. {company} ({comedy_counts[company]} Comedy movies)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfcb548",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = []\n",
    "for company in top_action_companies:\n",
    "    counts.append({'Company': company, 'Genre': 'Action', 'Count': action_counts[company]})\n",
    "for company in top_adventure_companies:\n",
    "    counts.append({'Company': company, 'Genre': 'Adventure', 'Count': adventure_counts[company]})\n",
    "for company in top_comedy_companies:\n",
    "    counts.append({'Company': company, 'Genre': 'Comedy', 'Count': comedy_counts[company]})\n",
    "counts_df = pd.DataFrame(counts)\n",
    "\n",
    "counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b364337c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create separate count DataFrames for each genre\n",
    "action_df = counts_df[counts_df['Genre'] == 'Action']\n",
    "adventure_df = counts_df[counts_df['Genre'] == 'Adventure']\n",
    "comedy_df = counts_df[counts_df['Genre'] == 'Comedy']\n",
    "\n",
    "# Create the figure and subplots\n",
    "f, axes = plt.subplots(1, 3, figsize=(18, 6), sharey = True)\n",
    "\n",
    "# Create the count plot for Action movies using seaborn\n",
    "sb.barplot(x=\"Company\", y=\"Count\", data=action_df, ax=axes[0],color = \"blue\")\n",
    "axes[0].set_xlabel('Companies')\n",
    "axes[0].set_ylabel('Movies')\n",
    "axes[0].set_title('Count Of Action Movies For Top 3 Actors')\n",
    "axes[0].set_xticklabels(axes[0].get_xticklabels(), rotation=90)\n",
    "\n",
    "# Create the count plot for Adventure movies using seaborn\n",
    "sb.barplot(x=\"Company\", y=\"Count\", data=adventure_df, ax=axes[1], color = \"green\")\n",
    "axes[1].set_xlabel('Companies')\n",
    "axes[1].set_ylabel('Movies')\n",
    "axes[1].set_title('Count Of Adventure Movies For Top 3 Actors')\n",
    "axes[1].set_xticklabels(axes[1].get_xticklabels(), rotation=90)\n",
    "\n",
    "# Create the count plot for Comedy movies using seaborn\n",
    "sb.barplot(x=\"Company\", y=\"Count\", data=comedy_df, ax=axes[2], color = \"red\")\n",
    "axes[2].set_xlabel('Companies')\n",
    "axes[2].set_ylabel('Movies')\n",
    "axes[2].set_title('Count Of Comedy Movies For Top 3 Actors')\n",
    "axes[2].set_xticklabels(axes[2].get_xticklabels(), rotation=90)\n",
    "\n",
    "plt.suptitle(\"Top 3 Production Companies by Genre\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40710b7b",
   "metadata": {},
   "source": [
    "# NLP using gpt2-medium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2aac4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed23e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_movies = merged_df['title'].tolist()\n",
    "\n",
    "# Define the lists for different genres\n",
    "adventure_list = []\n",
    "action_list = []\n",
    "comedy_list = []\n",
    "\n",
    "# Define the words to search for in each column\n",
    "genre_words = ['Adventure', 'Action', 'Comedy']\n",
    "\n",
    "# Loop through every row and column of the DataFrame\n",
    "for index, row in merged_df.iterrows():\n",
    "    match_genres = []  # Define an empty list to store the matching genres\n",
    "    for i in range(1, 8):\n",
    "        # Check if the genre column contains any of the genre_words\n",
    "        if row[f'genres_{i}'] in genre_words:\n",
    "            match_genres.append(row[f'genres_{i}'])\n",
    "    # Append the movie title to the corresponding list(s) based on the matching genres\n",
    "    if 'Adventure' in match_genres:\n",
    "        adventure_list.append(row['title'])\n",
    "    if 'Action' in match_genres:\n",
    "        action_list.append(row['title'])\n",
    "    if 'Comedy' in match_genres:\n",
    "        comedy_list.append(row['title'])\n",
    "\n",
    "# Print the resulting lists\n",
    "print(\"combined:\", top_movies)\n",
    "print()\n",
    "print(\"adventure:\", adventure_list)\n",
    "print()\n",
    "print(\"action:\", action_list)\n",
    "print()\n",
    "print(\"comedy:\", comedy_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fd0453",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install bs4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edf142d",
   "metadata": {},
   "source": [
    "Replace \"top_movies\" with the other 3 lists of movie titles when done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc35d440",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "count = 0\n",
    "with open(\"movie_transcripts_with_numbers.txt\", \"a\", encoding = \"utf-8\") as f:\n",
    "    for movie in top_movies:\n",
    "        # Format the URL for the movie script page\n",
    "        url = f\"http://www.imsdb.com/scripts/{movie.replace(' ', '-')}.html\"\n",
    "        \n",
    "        # Send a request to the URL and check for successful response\n",
    "        response = requests.get(url)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Failed to retrieve script for {movie}\")\n",
    "            continue\n",
    "        \n",
    "        # Use BeautifulSoup to parse the HTML response text\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        \n",
    "        # Extract the script text from the HTML tags\n",
    "        script_text = soup.find(\"td\", {\"class\": \"scrtext\"}).get_text()\n",
    "\n",
    "        # Count the number of words in the script text\n",
    "        word_count = len(script_text.split())\n",
    "        \n",
    "        # Check if the script has less than 1000 words, and skip the movie if it does\n",
    "        if word_count < 1000:\n",
    "            print(f\"{movie} skipped due to less than 1000 words\")\n",
    "            continue\n",
    "\n",
    "        \n",
    "        # Append the script text to the file\n",
    "        f.write(f\"Movie Title: {movie}\\n\\n\")\n",
    "        f.write(script_text)\n",
    "        f.write(\"\\n\\n\")\n",
    "\n",
    "        count += 1  # increment the count variable\n",
    "\n",
    "print(f\"Done! Scraped {count} movies.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48934961",
   "metadata": {},
   "outputs": [],
   "source": [
    "  # Open the input and output files\n",
    "with open('movie_transcripts_with_numbers.txt', 'r') as infile, open('movie_transcripts.txt', 'w') as outfile:\n",
    "    # Loop through each line in the input file\n",
    "    for line in infile:\n",
    "        # Remove any digits from the line\n",
    "        line = ''.join(c for c in line if not c.isdigit())\n",
    "        # Write the updated line to the output file\n",
    "        outfile.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dfca58",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"movie_transcripts.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "with open(\"movie_transcripts.txt\", \"w\") as f:\n",
    "    for line in lines:\n",
    "        f.write(line.strip() + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de4c697",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"movie_transcripts.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "with open(\"movie_transcripts.txt\", \"w\") as f:\n",
    "    for line in lines:\n",
    "        if line.replace(\".\", \"\").strip() != \"\":\n",
    "            f.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc858b61",
   "metadata": {},
   "source": [
    "1. Create folder /storage, /storage/data and /storage/models \n",
    "2. Transfer cleaned \"movie_transcripts.txt\" into data folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8141ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install transformers\n",
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7d24d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "from torch.utils.data import DataLoader, Dataset, RandomSampler, SequentialSampler\n",
    "from transformers import (\n",
    "    GPT2Config,\n",
    "    GPT2LMHeadModel,\n",
    "    GPT2PreTrainedModel,\n",
    "    GPT2Tokenizer,\n",
    "    PreTrainedModel,\n",
    "    PreTrainedTokenizer,\n",
    ")\n",
    "\n",
    "MODEL_CLASSES = {\"gpt2\": (GPT2Config, GPT2LMHeadModel, GPT2Tokenizer)}\n",
    "\n",
    "FILE_PATH = os.path.join(\"storage\", \"data\", \"movie_transcripts.txt\")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class ScriptData(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        tokenizer: PreTrainedTokenizer,\n",
    "        file_path: str,\n",
    "        block_size=512,\n",
    "        overwrite_cache=False,\n",
    "    ):\n",
    "        assert os.path.isfile(file_path)\n",
    "\n",
    "        block_size = block_size - (\n",
    "            tokenizer.model_max_length - tokenizer.max_len_single_sentence\n",
    "        )\n",
    "\n",
    "        directory, filename = os.path.split(file_path)\n",
    "\n",
    "        # change if args are added at later point\n",
    "        cached_features_file = os.path.join(\n",
    "            directory, \"gpt2\" + \"_\" + str(block_size) + \"_\" + filename\n",
    "        )\n",
    "\n",
    "        if os.path.exists(cached_features_file) and not overwrite_cache:\n",
    "            logger.info(\n",
    "                f\"Loading features from your cached file {cached_features_file}\"\n",
    "            )\n",
    "            with open(cached_features_file, \"rb\") as cache:\n",
    "                self.examples = pickle.load(cache)\n",
    "                logger.debug(\"Loaded examples from cache\")\n",
    "        else:\n",
    "            logger.info(f\"Creating features from file {filename} at {directory}\")\n",
    "\n",
    "            self.examples = []\n",
    "            with open(file_path, encoding=\"utf-8\") as f:\n",
    "                text = f.read()\n",
    "                logger.debug(\"Succesfully read text from file\")\n",
    "\n",
    "            tokenized_text = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(text))\n",
    "\n",
    "            for i in range(0, len(tokenized_text) - block_size + 1, block_size):\n",
    "                self.examples.append(\n",
    "                    tokenizer.build_inputs_with_special_tokens(\n",
    "                        tokenized_text[i : i + block_size]\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            logger.info(f\"Saving features into cached file {cached_features_file}\")\n",
    "            with open(cached_features_file, \"wb\") as cache:\n",
    "                \n",
    "                pickle.dump(self.examples, cache, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return torch.tensor(self.examples[item], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ef543c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, AdamW, get_linear_schedule_with_warmup, WEIGHTS_NAME, CONFIG_NAME\n",
    "import numpy as np\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f26ad0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b4cfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2-medium\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2-medium\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a79ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH = os.path.join(\"storage\",\"data\", \"movie_transcripts.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7462fe11",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ScriptData(tokenizer= tokenizer, file_path= FILE_PATH )\n",
    "script_loader = DataLoader(dataset,batch_size=4,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ed5528",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 7\n",
    "EPOCHS = 1\n",
    "LEARNING_RATE = 0.00002\n",
    "WARMUP_STEPS = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0188f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "model.train()\n",
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=WARMUP_STEPS, num_training_steps=-1)\n",
    "script_count = 0\n",
    "sum_loss = 0.0\n",
    "batch_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc06ca4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"./storage/models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d21c047",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    print(f\"EPOCH {epoch} started\" + '=' * 30)\n",
    "    for idx,script in enumerate(script_loader):\n",
    "        outputs = model(script.to(device), labels=script.to(device))\n",
    "        \n",
    "        loss, logits = outputs[:2]                        \n",
    "        loss.backward()\n",
    "        sum_loss = sum_loss + loss.detach().data\n",
    "                       \n",
    "        script_count = script_count + 1\n",
    "        if script_count == BATCH_SIZE:\n",
    "            script_count = 0    \n",
    "            batch_count += 1\n",
    "            optimizer.step()\n",
    "            scheduler.step() \n",
    "            optimizer.zero_grad()\n",
    "            model.zero_grad()\n",
    "            \n",
    "        if batch_count == 30:\n",
    "            model.eval()\n",
    "            print(f\"sum loss {sum_loss}\")\n",
    "            sample_outputs = model.generate(\n",
    "                                    bos_token_id=random.randint(1,30000),\n",
    "                                    do_sample=True,   \n",
    "                                    top_k=50, \n",
    "                                    max_length = 1000,\n",
    "                                    top_p=0.95, \n",
    "                                    num_return_sequences=1\n",
    "                                )\n",
    "\n",
    "            print(\"Output:\\n\" + 100 * '-')\n",
    "            for i, sample_output in enumerate(sample_outputs):\n",
    "                  print(\"{}: {}\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))\n",
    "\n",
    "            output_model_file = os.path.join(output_dir, WEIGHTS_NAME)\n",
    "            output_config_file = os.path.join(output_dir, CONFIG_NAME)\n",
    "\n",
    "            torch.save(model.state_dict(), output_model_file)\n",
    "            model.config.to_json_file(output_config_file)\n",
    "            tokenizer.save_vocabulary(output_dir)\n",
    "            \n",
    "            batch_count = 0\n",
    "            sum_loss = 0.0\n",
    "            model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3d5d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPT2LMHeadModel.from_pretrained(output_dir)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ec074e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a68bbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ScriptData(tokenizer= tokenizer, file_path= FILE_PATH )\n",
    "script_loader = DataLoader(dataset,batch_size=4,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5321b15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 7\n",
    "EPOCHS = 3\n",
    "LEARNING_RATE = 0.00002\n",
    "WARMUP_STEPS = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521f0905",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "model.train()\n",
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=WARMUP_STEPS, num_training_steps=-1)\n",
    "script_count = 0\n",
    "sum_loss = 0.0\n",
    "batch_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7cfdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    print(f\"EPOCH {epoch} started\" + '=' * 30)\n",
    "    for idx,script in enumerate(script_loader):\n",
    "        outputs = model(script.to(device), labels=script.to(device))\n",
    "        \n",
    "        loss, logits = outputs[:2]                        \n",
    "        loss.backward()\n",
    "        sum_loss = sum_loss + loss.detach().data\n",
    "                       \n",
    "        script_count = script_count + 1\n",
    "        if script_count == BATCH_SIZE:\n",
    "            script_count = 0    \n",
    "            batch_count += 1\n",
    "            optimizer.step()\n",
    "            scheduler.step() \n",
    "            optimizer.zero_grad()\n",
    "            model.zero_grad()\n",
    "            \n",
    "        if batch_count == 30:\n",
    "            model.eval()\n",
    "            print(f\"sum loss {sum_loss}\")\n",
    "            sample_outputs = model.generate(\n",
    "                                    bos_token_id=random.randint(1,30000),\n",
    "                                    do_sample=True,   \n",
    "                                    top_k=50, \n",
    "                                    max_length = 1000,\n",
    "                                    top_p=0.95, \n",
    "                                    num_return_sequences=1\n",
    "                                )\n",
    "\n",
    "            print(\"Output:\\n\" + 100 * '-')\n",
    "            for i, sample_output in enumerate(sample_outputs):\n",
    "                  print(\"{}: {}\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))\n",
    "\n",
    "            output_model_file = os.path.join(output_dir, WEIGHTS_NAME)\n",
    "            output_config_file = os.path.join(output_dir, CONFIG_NAME)\n",
    "\n",
    "            torch.save(model.state_dict(), output_model_file)\n",
    "            model.config.to_json_file(output_config_file)\n",
    "            tokenizer.save_vocabulary(output_dir)\n",
    "            \n",
    "            batch_count = 0\n",
    "            sum_loss = 0.0\n",
    "            model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089412c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_model_file = os.path.join(output_dir, WEIGHTS_NAME)\n",
    "output_config_file = os.path.join(output_dir, CONFIG_NAME)\n",
    "\n",
    "torch.save(model.state_dict(), output_model_file)\n",
    "model.config.to_json_file(output_config_file)\n",
    "tokenizer.save_vocabulary(output_dir)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ca62e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "import random\n",
    "from transformers import AutoModel, AutoTokenizer, AutoModelWithLMHead\n",
    "import os\n",
    "import json\n",
    "\n",
    "def load_model(model_dir=None):\n",
    "    if model_dir is None:\n",
    "      model_dir = './storage/models/'\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(model_dir)\n",
    "    model = GPT2LMHeadModel.from_pretrained(model_dir)\n",
    "    return model, tokenizer\n",
    "\n",
    "def generate(model, tokenizer, input_text=None, num_samples=1, max_length=1000):\n",
    "    model.eval()\n",
    "    \n",
    "    if input_text:\n",
    "        input_ids = tokenizer.encode(input_text, return_tensors='pt')\n",
    "        output = model.generate(\n",
    "            input_ids= input_ids,\n",
    "            do_sample=True,   \n",
    "            top_k=50, \n",
    "            max_length = max_length,\n",
    "            top_p=0.95, \n",
    "            num_return_sequences= num_samples\n",
    "        )\n",
    "    else:\n",
    "        output = model.generate(\n",
    "            bos_token_id=random.randint(1,50000),\n",
    "            do_sample=True,   \n",
    "            top_k=50, \n",
    "            max_length = max_length,\n",
    "            top_p=0.95, \n",
    "            num_return_sequences=num_samples\n",
    "\n",
    "        )\n",
    "\n",
    "\n",
    "    decoded_output = []\n",
    "    for sample in output:\n",
    "        decoded_output.append(tokenizer.decode(\n",
    "            sample, skip_special_tokens=True))\n",
    "\n",
    "    return decoded_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6793c363",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, tokenizer = load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c56482e",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"The quick brown fox jumps over the lazy dog.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800b26e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = generate(model,tokenizer,input_text=context,max_length=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f86ccac",
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in sample:\n",
    "    print(line)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
